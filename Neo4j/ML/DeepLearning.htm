<!DOCTYPE html>
<html>
	<head>
		<title>Machine Learning</title>
		<link rel="stylesheet" href="css/atelier-sulphurpool-light.css" type="text/css">
		<script src="js/google-code-prettify/run_prettify.js?autoload=true&amp;lang=css"></script>
		<style>
			div.title {color: navy; font-weight: bold; width: 80%; font-size: 32px; text-align: center; position: relative; margin: auto;}
			div.subtitle {color: navy; font-weight: bold; width: 80%; font-size: 24px; text-align: position: relative; margin: auto;}
			div.block {color: navy; font-weight: bold; width: 80%; border-style: solid; padding: 5px; position: relative; margin: 10px auto; border-radius: 5px;}
		</style>
	</head>
	<body>
		<div class = "title">
			Deep Learning
		</div>

		<div class = "subtitle">Courses</div>
		<div class = "block">
			<ul>
				<li>CS231n, Feifei Li
					<ul>
						<li><a href = "http://cs231n.github.io/">Lecture</a></li>
						<li><a href = "https://www.youtube.com/watch?v=2uiulzZxmGg">Videos</a></li>
					</ul>
				</li>
			</ul>
		</div>

		<div class = "subtitle">Tutorial</div>
		<div class = "block">
			<ul>
				<li><a href = "http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf">Deep Learning Tutorial, ICML 2013, Yenn LeCun</a></li>
				<li><a href = "https://sites.google.com/site/deeplearningcvpr2014/">TUTORIAL ON DEEP LEARNING FOR VISION</a></li>
				<li><a href = "http://deeplearning.net/tutorial/deeplearning.pdf">LISA lab, University of Montreal</a></li>
				<li>CNN
					<ul>
						<li>A Beginner's Guide To Understanding Convolutional Neural Networks
							<ul>
								<li><a href = "https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/">Part 1</a>, <a href = "https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/">Part 2</a>, <a href = "https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html">Part 3</a></li>
								<li>Convolution Layer</li>
								<li>Pooling Layer</li>
								<li>ReLU Layer</li>
								<li><a href = "http://www.jmlr.org/papers/volume15/srivastava14a.old/source/srivastava14a.pdf">Dropout Layer</a></li>
								<li><a href = "https://en.wikipedia.org/wiki/Softmax_function">Softmax</a></li>
								<li>Transfer Learning</li>
								<li><a href = "https://stats.stackexchange.com/questions/153696/data-augmentation-techniques-for-general-datasets">data augmentation techniques</a></li>
								<li><a href = "http://ruder.io/optimizing-gradient-descent/">An overview of gradient descent optimization algorithms</a></li>
							</ul>
						</li>
						<li><a href = "https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59">CNN by Keras</a></li>
					</ul>
				</li>
				<li>FCNN
					<ul>
						<li><a href = "http://rnd.azoft.com/object-detection-fully-convolutional-neural-networks/">Architecture</a></li>
					</ul>
				</li>
				<li>R-CNN
					<ul>
						<li><a href = "https://blog.athelas.com/a-brief-history-of-cnns-in-image-segmentation-from-r-cnn-to-mask-r-cnn-34ea83205de4">History of RCNN</a></li>
					</ul>
				</li>
				<li><a href = "https://stats.stackexchange.com/questions/114385/what-is-the-difference-between-convolutional-neural-networks-restricted-boltzma">Autoencoder, RBM, CNN</a></li>
				<li><a href = "https://blog.vize.ai/how-to-prepare-images-for-a-training-dataset-f6889433249b">How to prepare images for a training dataset?</a></li>
				<li><a href = "http://ufldl.stanford.edu/eccv10-tutorial/">ECCV-2010 Tutorial: Feature Learning for Image Classification</a></li>
			</ul>
		</div>

		<div class = "subtitle">Papers</div>
		<div class = "block">
			<li><a href = "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf">Yenn LeCun 1998</a></li>
			<li><a href = "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"><span style = "color:red">*</span>Geoffrey E. Hinton, AlexNet 2012</a>
				<ul>
					<li><a href = "https://www.researchgate.net/figure/312593963_fig5_Figure-27-CNN-Architecture-from-AlexNet-32">AlexNet Architecture</a></li>
				</ul>
			</li>
			<li><a href = "https://arxiv.org/pdf/1311.2901v3.pdf">Rob Fergus, ZF Net, 2013</a>, DeConvNet</li>
			<li><a href = "https://arxiv.org/pdf/1409.1556v6.pdf">Karen Simonyan, VGG Net, 2014</a>, image classification and localization</li>
			<li><a href = "http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf">GoogleLeNet 2015</a>, Inception Module</li>
			<li><a href = "https://arxiv.org/pdf/1512.03385v1.pdf">Kaiming He, Microsoft ResNet 2015</a>, 152 layer</li>
			<li><a href = "https://arxiv.org/pdf/1311.2524v5.pdf">Ross Girshick, RCNN 2013</a></li>
			<li><a href = "https://arxiv.org/pdf/1504.08083.pdf">Ross Girshick, Fast RCNN 2014</a></li>
			<li><span style = "color:red">*</span> <a href = "https://arxiv.org/pdf/1506.01497v3.pdf">Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun, Faster RCNN 2015</a></li>
			<li><a href = "https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf">Jonathan Long, Fully Convolutional Networks for Semantic Segmentation</a>, FCN, 2016</li>
			<li><a href = "https://arxiv.org/pdf/1606.00373.pdf">Deeper Depth Prediction with Fully Convolutional Residual Networks</a></li>
		</div>

		<div class = "subtitle">Books</div>
		<div class = "block">
		</div>

		<div class = "subtitle">Softwares</div>
		<div class = "block">
			<li><a href = "http://caffe.berkeleyvision.org/">Caffe</a>, <a href = "http://caffe.berkeleyvision.org/tutorial/">Caffe Tutorial I</a>, <a href = "http://tutorial.caffe.berkeleyvision.org/">Caffee Tutorial II</a></li>
			<li>GoogleLeNet</li>
		</div>

		<div class = "subtitle">Datasets</div>
		<div class = "block">
			<ul>
				<li><a href = "http://www.image-net.org/download-imageurls">ImageNet</a>, 22,000 categories
					<ul>
						<li><a href = "http://image-net.org/tutorials/cvpr2015/">Large Scale Visual Recognition Challenge Tutorial</a>
							<ul>
								<li>Image Classification, 1000 classes, one class per image, no bounding boxes</li>
								<li>Single Object Localization, 1000 classes, one class per image, bounding boxes</li>
								<li>Object Detection, 200 classes, all classes per image, bounding boxes</li>
							</ul>
						</li>
					</ul>
				</li>
				<li><a href = "http://cs.nyu.edu/~silberman/datasets/nyu_depth_v2">NYU Depth Dataset V2</a></li>
			</ul>
		</div>

		<div class = "subtitle">People</div>
		<div class = "block">
			<li><a href = "http://www.cs.toronto.edu/~hinton/">Geoffrey E. Hinton</a>, University of Toronto</li>
			<li><a href = "http://cs.nyu.edu/~silberman/">Nathan Silberman</a>, TensorFlow-Slim</li>
		</div>
	</body>
</html>
