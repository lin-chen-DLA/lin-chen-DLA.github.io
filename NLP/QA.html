<!DOCTYPE html>

<html>

	<head>
        <title>Python</title>
        <link rel="stylesheet" href="../css/atelier-sulphurpool-light.css" type="text/css">
        <script src="../js/google-code-prettify/run_prettify.js?autoload=true&amp;lang=css"></script>
        <style>
            div.title {color: navy; font-weight: bold; width: 80%; font-size: 32px; text-align: center; position: relative; margin: auto;}
            div.subtitle {color: navy; font-weight: bold; width: 80%; font-size: 24px; text-align: position: relative; margin: auto;}
            div.block {color: navy; font-weight: bold; width: 80%; border-style: solid; padding: 5px; position: relative; margin: 10px auto; border-radius: 5px;}
            span {color:red; font-weight: bold;}
        </style>
    </head>

	<body>
		<div class = "title">
			Question Answering
		</div>

        <div class = "block">
            <li>Find accurate answers to questions based on a given context or knowledge base</li>
        </div>
        <div class = "subtitle">Use BERT</div>
		<div class = "block">
            <li><span>Use specific tokenizer class and model class</span></li>
		<pre class = "prettyprint linenums">
from transformers import BertTokenizerFast, BertForQuestionAnswering
import torch

# Load a pre-trained BERT model fine-tuned for question answering
model_name = "bert-large-uncased-whole-word-masking-finetuned-squad"
tokenizer = BertTokenizerFast.from_pretrained(model_name)
model = BertForQuestionAnswering.from_pretrained(model_name)

context = """
Hugging Face is a technology company based in New York and Paris. It is known for creating tools that allow 
developers to utilize machine learning models more easily, especially in the fields of natural language processing 
and computer vision. Their popular 'transformers' library provides state-of-the-art pre-trained models that can 
be fine-tuned for various applications, including text classification, question answering, and text generation.
"""
question = "What is Hugging Face known for?"

# Tokenize the input (question and context) and prepare the input IDs
inputs = tokenizer(question, context, return_tensors="pt")

# Get start and end logits
with torch.no_grad():
    outputs = model(**inputs)
    start_logits = outputs.start_logits
    end_logits = outputs.end_logits

# Find the start and end of the answer
start_index = torch.argmax(start_logits)
end_index = torch.argmax(end_logits)

tokens = inputs['input_ids'][0][start_index:end_index]
tokenizer.decode(tokens)
        </pre>
        </div>
		<div class = "block">
            <li><span>Use AutoTokenizer and AutoModel</span></li>
		<pre class = "prettyprint linenums">
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
import torch

# Load a pre-trained BERT model fine-tuned for question answering
model_name = "bert-large-uncased-whole-word-masking-finetuned-squad"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForQuestionAnswering.from_pretrained(model_name)

context = """
Hugging Face is a technology company based in New York and Paris. It is known for creating tools that allow 
developers to utilize machine learning models more easily, especially in the fields of natural language processing 
and computer vision. Their popular 'transformers' library provides state-of-the-art pre-trained models that can 
be fine-tuned for various applications, including text classification, question answering, and text generation.
"""
question = "What is Hugging Face known for?"

# Tokenize the input (question and context) and prepare the input IDs
inputs = tokenizer(question, context, return_tensors="pt")

# Get start and end logits
with torch.no_grad():
    outputs = model(**inputs)
    start_logits = outputs.start_logits
    end_logits = outputs.end_logits

# Find the start and end of the answer
start_index = torch.argmax(start_logits)
end_index = torch.argmax(end_logits)

tokens = inputs['input_ids'][0][start_index:end_index]
tokenizer.decode(tokens)
        </pre>
        </div>
		<div class = "block">
            <li><span>Use pipeline</span>
            </li>
		<pre class = "prettyprint linenums">
from transformers import pipeline

# Load the question-answering pipeline with the specified BERT model
qa_pipeline = pipeline("question-answering", model="bert-large-uncased-whole-word-masking-finetuned-squad")

# Define the context and question
context = """
Hugging Face is a technology company based in New York and Paris. It is known for creating tools that allow 
developers to utilize machine learning models more easily, especially in the fields of natural language processing 
and computer vision. Their popular 'transformers' library provides state-of-the-art pre-trained models that can 
be fine-tuned for various applications, including text classification, question answering, and text generation.
"""
question = "What is Hugging Face known for?"

# Use the pipeline to answer the question based on the context
answer = qa_pipeline(question=question, context=context)

# Print the answer
print(f"Question: {question}")
print(f"Answer: {answer['answer']}")
        </pre>
        </div>
    </body>
</html>
